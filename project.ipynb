{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ecf52d5",
   "metadata": {},
   "source": [
    "## Import Library and Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b57bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fafdc4cf-0818-4015-bc55-b8e24bbfe4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ea0edc-4ebe-4684-986c-7c44447ca8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'seg_train/seg_train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'seg_test/seg_test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = './intel/'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['seg_train/seg_train', 'seg_test/seg_test']}\n",
    "\n",
    "train_sizes = len(image_datasets['seg_train/seg_train'])\n",
    "test_sizes = len(image_datasets['seg_test/seg_test']) \n",
    "\n",
    "class_names = image_datasets['seg_train/seg_train'].classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f109ad2d-41b7-477a-9643-bfb953a99cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['building', 'forest', 'mountain']\n"
     ]
    }
   ],
   "source": [
    "art_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "art_dir = './'\n",
    "art_datasets = {x: datasets.ImageFolder(os.path.join(art_dir, x), art_transforms[x]) for x in ['train', 'valid', 'test']}\n",
    "\n",
    "train_sizes = len(art_datasets['train']) \n",
    "valid_sizes = len(art_datasets['valid']) \n",
    "test_sizes = len(art_datasets['test']) \n",
    "\n",
    "art_names = art_datasets['train'].classes\n",
    "print(art_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "339f51ed-3c14-4575-af41-3bc9a546e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data                  \n",
    "art_train_dataset = DataLoader(art_datasets['train'], batch_size=32,shuffle=True)\n",
    "art_valid_dataset = DataLoader(art_datasets['valid'], batch_size=32,shuffle=True)\n",
    "art_test_dataset = DataLoader(art_datasets['test'], batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edba96c-98d0-4b8e-9cbc-79f6fefe209d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using pre-trained model from imageNet:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c4ced2-5eb0-4b15-b2e4-9af5c15ca021",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model: VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c3f2bc9-823e-49b2-a03f-c9fadd40e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg19 = models.vgg19(weights='DEFAULT').to(device)\n",
    "for param in model_vgg19.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb9abb91-2b2c-4f32-8231-36d34af1d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg19.classifier[6] = nn.Linear(model_vgg19.classifier[6].in_features, len(art_names)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_vgg19.classifier.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c1d59f7-69f6-4a1c-84fd-857c7766d10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2828cb-08f9-4672-a99c-aaf4fda826dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Freezed Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1aa9eebb-3291-44a5-882e-4a4f5ea12614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " Loss: 0.9492 Acc: 0.562\n",
      "Epoch 2/20\n",
      " Loss: 1.7787 Acc: 0.500\n",
      "Epoch 3/20\n",
      " Loss: 0.9167 Acc: 0.688\n",
      "Epoch 4/20\n",
      " Loss: 0.9054 Acc: 0.656\n",
      "Epoch 5/20\n",
      " Loss: 0.6703 Acc: 0.750\n",
      "Epoch 6/20\n",
      " Loss: 1.4295 Acc: 0.594\n",
      "Epoch 7/20\n",
      " Loss: 1.1835 Acc: 0.656\n",
      "Epoch 8/20\n",
      " Loss: 0.3525 Acc: 0.812\n",
      "Epoch 9/20\n",
      " Loss: 1.2239 Acc: 0.719\n",
      "Epoch 10/20\n",
      " Loss: 0.4936 Acc: 0.719\n",
      "Epoch 11/20\n",
      " Loss: 1.2838 Acc: 0.688\n",
      "Epoch 12/20\n",
      " Loss: 0.6276 Acc: 0.719\n",
      "Epoch 13/20\n",
      " Loss: 0.5349 Acc: 0.781\n",
      "Epoch 14/20\n",
      " Loss: 0.7001 Acc: 0.656\n",
      "Epoch 15/20\n",
      " Loss: 0.4483 Acc: 0.719\n",
      "Epoch 16/20\n",
      " Loss: 0.4555 Acc: 0.750\n",
      "Epoch 17/20\n",
      " Loss: 0.9441 Acc: 0.625\n",
      "Epoch 18/20\n",
      " Loss: 0.4753 Acc: 0.781\n",
      "Epoch 19/20\n",
      " Loss: 1.0696 Acc: 0.688\n",
      "Epoch 20/20\n",
      " Loss: 1.1867 Acc: 0.656\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # train data\n",
    "    model_vgg19.train()  \n",
    "    for X, y in art_train_dataset:\n",
    "        if torch.cuda.is_available():\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward\n",
    "        outputs = model_vgg19(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        # backward + optimize \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # valid data\n",
    "    valid_loss = 0.0\n",
    "    correct = 0\n",
    "    model_vgg19.eval()\n",
    "    # Iterate over data.\n",
    "    for X, y in art_valid_dataset:\n",
    "        if torch.cuda.is_available():\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        # forward\n",
    "        outputs = model_vgg19(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        valid_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += torch.sum(preds == y) \n",
    "    \n",
    "    epoch_loss = valid_loss / len(art_valid_dataset)\n",
    "    epoch_acc = correct / (len(art_valid_dataset) * 32)\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    print(f' Loss: {epoch_loss:.4f} Acc: {epoch_acc:.3f}')\n",
    "    if epoch_acc >= best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        torch.save(model_vgg19.state_dict(), 'freezed_vgg19_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374c4098-6509-45b5-ad58-dfd5ef0dae58",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Unfreezed Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5acce856-e160-408e-8c84-7c03d28968da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg19.load_state_dict(torch.load('freezed_vgg19_model.pt'))\n",
    "model_vgg19 = model_vgg19.to(device)\n",
    "for param in model_vgg19.parameters():\n",
    "    param.requires_grad = True\n",
    "unfreeze_criterion = nn.CrossEntropyLoss()\n",
    "unfreeze_optimizer = torch.optim.SGD(model_vgg19.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bcf91dd0-b20a-41e5-b63e-49a8fd684629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " Loss: 0.5709 Acc: 0.719\n",
      "Epoch 2/20\n",
      " Loss: 0.8344 Acc: 0.812\n",
      "Epoch 3/20\n",
      " Loss: 0.9485 Acc: 0.562\n",
      "Epoch 4/20\n",
      " Loss: 0.6840 Acc: 0.719\n",
      "Epoch 5/20\n",
      " Loss: 0.5871 Acc: 0.719\n",
      "Epoch 6/20\n",
      " Loss: 0.7628 Acc: 0.719\n",
      "Epoch 7/20\n",
      " Loss: 0.5368 Acc: 0.781\n",
      "Epoch 8/20\n",
      " Loss: 0.3610 Acc: 0.812\n",
      "Epoch 9/20\n",
      " Loss: 0.3807 Acc: 0.812\n",
      "Epoch 10/20\n",
      " Loss: 0.5681 Acc: 0.781\n",
      "Epoch 11/20\n",
      " Loss: 0.5133 Acc: 0.844\n",
      "Epoch 12/20\n",
      " Loss: 0.5542 Acc: 0.812\n",
      "Epoch 13/20\n",
      " Loss: 0.8281 Acc: 0.719\n",
      "Epoch 14/20\n",
      " Loss: 0.6281 Acc: 0.781\n",
      "Epoch 15/20\n",
      " Loss: 0.6981 Acc: 0.781\n",
      "Epoch 16/20\n",
      " Loss: 0.7552 Acc: 0.781\n",
      "Epoch 17/20\n",
      " Loss: 0.7273 Acc: 0.781\n",
      "Epoch 18/20\n",
      " Loss: 0.7940 Acc: 0.781\n",
      "Epoch 19/20\n",
      " Loss: 0.7566 Acc: 0.750\n",
      "Epoch 20/20\n",
      " Loss: 0.5276 Acc: 0.750\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # train data\n",
    "    model_vgg19.train()  \n",
    "    for X, y in art_train_dataset:\n",
    "        if torch.cuda.is_available():\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        # zero the parameter gradients\n",
    "        unfreeze_optimizer.zero_grad()\n",
    "        # forward\n",
    "        outputs = model_vgg19(X)\n",
    "        loss = unfreeze_criterion(outputs, y)\n",
    "        # backward + optimize \n",
    "        loss.backward()\n",
    "        unfreeze_optimizer.step()\n",
    "\n",
    "    # valid data\n",
    "    valid_loss = 0.0\n",
    "    correct = 0\n",
    "    model_vgg19.eval()\n",
    "    # Iterate over data.\n",
    "    for X, y in art_valid_dataset:\n",
    "        if torch.cuda.is_available():\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        # forward\n",
    "        outputs = model_vgg19(X)\n",
    "        loss = unfreeze_criterion(outputs, y)\n",
    "        valid_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += torch.sum(preds == y) \n",
    "    \n",
    "    epoch_loss = valid_loss / len(art_valid_dataset)\n",
    "    epoch_acc = correct / (len(art_valid_dataset) * 32)\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    print(f' Loss: {epoch_loss:.4f} Acc: {epoch_acc:.3f}')\n",
    "    # stop training according to valid dataset\n",
    "    if epoch_acc >= best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        torch.save(model_vgg19.state_dict(), 'unfreeze_vgg19_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0f442d-62fc-490c-a1da-ea72634b0f69",
   "metadata": {},
   "source": [
    "### Pre-trained on intel image dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1a69ae-928a-4dcd-946b-e6440cafd792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
